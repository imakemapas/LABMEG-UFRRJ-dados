```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### 🌍 ─────────────────────────────────────────────── 🌍

#### 🌍 THERESA ROCCO PEREIRA BARBOSA

#### 🌍 Brasileira | Geocientista | Dados

#### 🌍 imakemapas@outlook.com.br | +55 24 998417085

#### 🌍 2025-02-03

#### 🌍 ─────────────────────────────────────────────── 🌍

<br>

### **INTEGRAÇÃO DE DADOS CIENTÍFICOS LEGADOS: PADRONIZAÇÃO DE COORDENADAS GEOGRÁFICAS**

A integração de dados científicos legados, especialmente aqueles com informações georreferenciadas, apresenta desafios. Um dos problemas mais comuns é a inconsistência no formato das coordenadas de latitude e longitude. Essas inconsistências podem surgir devido a diferenças nos sistemas de coleta de dados, variações culturais na representação de coordenadas ou até mesmo erros de digitação.

Este código foi desenvolvido para enfrentar esses desafios, oferecendo uma solução que padroniza as coordenadas geográficas em formato decimal. O processo envolve a leitura dos dados a partir de uma planilha Excel, renomeando colunas e removendo linhas com valores ausentes. Remoção de espaços desnecessários – além de tratar casos em que o ponto decimal pode estar ausente, convertendo números inteiros grandes no formato decimal esperado. O objeto final é salvo como um shapefile, garantindo que os dados espaciais integrados estejam prontos para análises geográficas complexas e mapeamentos.

O fluxo trabalho é dividido nas etapas:

1. Carregamento e limpeza dos dados
2. Padronização de símbolos e formatos
3. Exportação dos dados corrigidos

A combinação de técnicas de manipulação de strings e transformação de coordenadas em R garante que os dados estejam padronizados e prontos para uso em estudos e aplicações geoespaciais. Este fluxo de trabalho torna o processo replicável, podendo ser adaptado a outros conjuntos de dados legados que enfrentem desafios semelhantes.

##### **0. CARREGAMENTO BIBLIOTECAS NECESSÁRIAS -----------------------------------**
```{r message=FALSE, warning=FALSE}
library(dplyr)       # Para manipulação de dados
library(readxl)      # Para leitura de arquivos Excel
library(stringr)     # Para manipulação de strings (texto)
library(sf)          # Para trabalhar com dados espaciais
```

##### **1. CARREGAMENTO E LIMPEZA DOS DADOS ---------------------------------------**

```{r}
# Leitura da planilha
dft <- readxl::read_excel("../raw_data/tabela_sem_ponto.xlsx")

# Renomeia 
dft <- dft |> 
  dplyr::rename(Sample_ID = `Sample ID`)

# Renomeia e seleciona as colunas necessárias
dfc <- dft |> 
  dplyr::select(Sample_ID, Lat, Long) |> 
  na.exclude()
```

```{r}
# Checa numero de linhas noS dataframes inicial e com NA removidos.
nrow(dft)
nrow(dfc)
```

```{r}
# Função para padronizar coordenadas
padronizar_coordenadas <- function(coord) {
  coord <- as.character(coord) |>  
    str_trim()                    # Remove espaços extras
  
  # Adiciona ponto decimal se estiver ausente em valores numéricos grandes
  if (str_detect(coord, "^-?\\d{5,}$")) {
    coord <- str_replace(coord, "(-?\\d{2})(\\d+)", "\\1.\\2")
  }
  
  return(as.numeric(coord))
}

# Aplica a função para corrigir Lat e Long
dfc <- dfc |> 
  dplyr::mutate(
    Lat = sapply(Lat, padronizar_coordenadas),
    Long = sapply(Long, padronizar_coordenadas)
  )

str(dfc)
```

##### **3. EXPORTAÇÃO DOS DADOS CORRIGIDOS ---------------------------------------**

```{r}
# Renomear colunas em dff
dff <- dfc |> 
  dplyr::rename(LATf = Lat, LONGf = Long) 

# Renomear colunas em dft
dft <- dft |> 
  dplyr::rename(LATi = Lat, LONGi = Long)

names(dft)
names(dff)
```

```{r}
dff <- inner_join(dff, dft, by = "Sample_ID")
names(dff)
```

```{r}
dff <- dff |> dplyr::mutate(LATtemp = LATf, LONGtemp = LONGf)
str(dff)
```

```{r}
dff <- dff |> 
  mutate(
    LOI = as.numeric(LOI),
    Fe2O3 = as.numeric(Fe2O3),
    FeO = as.numeric(FeO)
    ) |>  dplyr::rename(Itrio = Y)
str(dff)
```

```{r}
summary(dff)
```

```{r}
# CRS Final
## O Instituto Brasileiro de Geografia e Estatística (IBGE) recomenda a Projeção Equivalente de Albers 
## com o datum horizontal SIRGAS2000 para a preservação e o cálculo de áreas no território brasileiro
## Referência: 'Informações técnicas e legais para a utilização dos dados publicados' (IBGE, 2023) 
## https://biblioteca.ibge.gov.br/index.php/biblioteca-catalogo?view=detalhes&id=2101998 - Access in 2024 November
final_crs <- 'PROJCS["Conica_Equivalente_de_Albers_Brasil",
    GEOGCS["GCS_SIRGAS2000",
    DATUM["D_SIRGAS2000",
    SPHEROID["Geodetic_Reference_System_of_1980",6378137,298.2572221009113]],
    PRIMEM["Greenwich",0],
    UNIT["Degree",0.017453292519943295]],
    PROJECTION["Albers"],
    PARAMETER["standard_parallel_1",-2],
    PARAMETER["standard_parallel_2",-22],
    PARAMETER["latitude_of_origin",-12],
    PARAMETER["central_meridian",-54],
    PARAMETER["false_easting",5000000],
    PARAMETER["false_northing",10000000],
    UNIT["Meter",1]]'
```

```{r}
# Converte o dataframe final diretamente para um SpatVector
vect <- terra::vect(dff, geom = c("LONGtemp", "LATtemp"), crs = "EPSG:4326")

# Reprojeta para o sistema de coordenadas final
vect_ibge <- terra::project(vect, final_crs)

# Extrai as coordenadas e adiciona como colunas
coords <- terra::crds(vect_ibge)
vect_ibge$X <- coords[, 1]
vect_ibge$Y <- coords[, 2]

```

```{r}
# Salva o objeto espacial como um shapefile
terra::writeVector(vect_ibge, "../processed_data/grau_sem_ponto_final.shp", overwrite = TRUE)
```